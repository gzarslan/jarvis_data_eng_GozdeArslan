{
  "metadata": {
    "name": "Jarvis Hive Project",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Query GS data\n- Created a hive table (`wdi_gs`) against the GS wdi_2016 data.\n- Counting number of rows from the wdi_gs table \n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP TABLE IF EXISTS wdi_gs\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "CREATE EXTERNAL TABLE wdi_gs\r\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\r\nROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 LINES TERMINATED BY \u0027\\n\u0027\r\nLOCATION \u0027gs://jarvis_data_eng_gozde/datasets/wdi_2016\u0027\r\nTBLPROPERTIES (\"skip.header.line.count\"\u003d\"1\");\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "-- show table meta data\r\nDESCRIBE FORMATTED wdi_gs;"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "-- counts the number of rows from wdi_gs table\n\nSELECT count(countryName) as count  FROM wdi_gs"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Load GS data to HDFS"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP TABLE IF EXISTS wdi_csv_text\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nCREATE EXTERNAL TABLE wdi_csv_text\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 LINES TERMINATED BY \u0027\\n\u0027\nLOCATION \u0027hdfs:///user/garslan/hive/wdi/wdi_csv_text\u0027;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "- Query that loads data from wdi_gs table to wdi_csv_text table.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "INSERT OVERWRITE TABLE wdi_csv_text\nSELECT * FROM wdi_gs\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n- Check HDFS file size for wdi_csv_text file "
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n hdfs dfs -ls -h /user/garslan/hive/wdi/wdi_csv_text"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n hdfs dfs -du -s -h /user/garslan/hive/wdi/wdi_csv_text\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT count(countryName) as count  FROM wdi_csv_text\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n- Clear filesystem cache and execute the count query again."
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh \n\necho 3 | sudo tee /proc/sys/vm/drop_caches\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Hive vs Bash\n\nBash took 3 seconds to execute, while Hive took 20 seconds. The total time  of  the Hive technique was longer. Because of the cost of parsing queries, developing an implementation of execution plan, and performing  Hadoop  Map Reduce task."
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n#SSH to master node\ncd ~\nhdfs  dfs -get  hdfs:///user/garslan/hive/wdi/wdi_csv_text .\ncd wdi_csv_text\n#calculate current directory size\ndu -ch .\n#1.8G\ttotal\n\n#clear fs cache\necho 3 | sudo tee /proc/sys/vm/drop_caches\n#bash row count\ndate +%s \u0026\u0026 cat * | wc \u0026\u0026 date +%s\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\ncd ~\nhdfs  dfs -get  hdfs:///user/garslan/hive/wdi/wdi_csv_text ."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Parsing Issue solved\n\nThe indicatorName column may contain commas that causes problem when parsing data by using LazysimpleSerDe. In this case opencsvSerDe should be used to parse data into columsn in the Hive table. \n\nCreate an external table wdi_gs_debug with one column without any SerDe parsing\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%hive\nSELECT distinct(indicatorcode)\nFROM wdi_csv_text\nORDER BY indicatorcode\nLIMIT 20 \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "1. Identify issue by creating a debug table\n"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive \n\n-- 1a. Create an external table wdi_gs_debug with one column without any SerDe parsing\n\nCREATE EXTERNAL TABLE wdi_gs_debug\n(line STRING)\nROW FORMAT DELIMITED LINES TERMINATED BY \u0027\\n\u0027\nSTORED AS TEXTFILE\nLOCATION \u0027hdfs:///user/garslan/hive/wdi/wdi_csv_text\u0027;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n-- 1b.Query the line that have parsing issue\n\nSELECT line FROM wdi_gs_debug\nWHERE line like \"%\\(\\% of urban population\\)\\\"%\" "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "2. Create a Table with OpenCSV SerDe"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n\n-- 2a.Create wdi_opencsv_gs source table (load GS data with OpenCSVSerde)\n\nCREATE EXTERNAL TABLE wdi_opencsv_gs\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nLOCATION \u0027gs://jarvis_data_eng_gozde/datasets/wdi_2016\u0027\nTBLPROPERTIES (\"skip.header.line.count\"\u003d\"1\");\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n-- 2b. Create wdi_opencsv_text destination table (output table with hdfs location)\n\nCREATE EXTERNAL TABLE wdi_opencsv_text\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nSTORED AS TEXTFILE\nLOCATION \u0027hdfs:///user/garslan/hive/wdi/wdi_csv_text\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n-- 2c.A HiveQL which Load data from wdi_opencsv_gs to \nINSERT OVERWRITE TABLE wdi_opencsv_text\nSELECT * FROM wdi_opencsv_gs"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n-- 2d. Verifying the data parsing has been done correctly.\n\nSELECT distinct(indicatorcode)\nFROM wdi_opencsv_text\nORDER BY indicatorcode\nLIMIT 20 \n"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n\n-- Comparation of  execution time between wdi_opencsv_text and wdi_csv_text\n-- Usage of opencsvSerde makes execution slower than LazysimpleSerDe.\n\n SELECT count(countryName) FROM wdi_opencsv_text\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# OpenCSVSerde limitaion\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "- Compare metadata of two file \n"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive \n\nDESCRIBE FORMATTED wdi_opencsv_text \n"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDESCRIBE FORMATTED wdi_csv_text"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n-- Create a view on top of wdi_opencsv_text to cast specific columns to correct data type.\n\nDROP VIEW IF EXISTS wdi_opencsv_text_view;\n\nCREATE VIEW IF NOT EXISTS wdi_opencsv_text_view\nAS\nSELECT cast(year as INTEGER), countryName, countryCode,indicatorName, indicatorCode,cast(indicatorValue as Float) from wdi_opencsv_text"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n--Check if the data types casted properly\nDESCRIBE FORMATTED wdi_opencsv_text_view    "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 2015 Canada GDP Growth HQL\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "- Find 2015 GDP growth (annual %) for Canada.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT year ,countryName , indicatorValue AS GDP_growth_value\nFROM wdi_opencsv_text_view\nWHERE indicatorName LIKE \"%GDP growth%\" AND year \u003d2015 AND countryName \u003d\u0027Canada\u0027 \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Hive Partitions"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "For big datasets, reading across each row may take longer, which could be an issue in the further process. Therefore, using partitions that makes a simple way to query a set of data. Tables or partitions are split into buckets to provide the data more structure and allow for more efficient searching.Bucketing is based on the value of the hash function of a table column. "
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n\n-- Create new table \u0027wdi_opencsv_text_partions\u0027 that partitioned by year\nset hive.exec.dynamic.partition.mode\u003dnonstrict;\nDROP TABLE IF EXISTS wdi_opencsv_text_partitions;\nCREATE EXTERNAL TABLE wdi_opencsv_text_partitions\n(countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nPARTITIONED by (year INTEGER)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nLOCATION \u0027hdfs:///user/garslan/hive/wdi/wdi_opencsv_text_partitions\u0027 ;"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n--Setting up the dynamic partition\n\nset hive.exec.dynamic.partition.mode\u003dnonstrict;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n\n--Setting up the dynamic partition\n\nset hive.exec.dynamic.partition.mode\u003dnonstrict;\n\n--Load data from wdi_opencsv_text to wdi_opencsv_text_partitions\nINSERT OVERWRITE TABLE wdi_opencsv_text_partitions PARTITION (year)\nSELECT countryName,countryCode,indicatorName, indicatorCode, indicatorValue,year\nFROM wdi_opencsv_text\n"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n#Inspecting  how many partitions have been created for by using HDFS commands as partitions are sub-directory in the HDFS\n hdfs dfs -ls -h /user/garslan/hive/wdi/wdi_opencsv_text_partitions\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive \n-- Retrive data \nSELECT year ,countryName , indicatorValue AS GDP_growth_value\nFROM wdi_opencsv_text_view\nWHERE indicatorName LIKE \"%GDP growth%\" AND year \u003d2015 AND countryName \u003d\u0027Canada\u0027 "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Columnar File Optimization\n\n- Optimizing HQL query using columnar file. \n"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDROP TABLE IF EXISTS wdi_csv_parquet\n"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n--Create table\nCREATE EXTERNAL TABLE wdi_csv_parquet\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nSTORED AS PARQUET\nLOCATION \u0027hdfs:///user/garslan/hive/wdi/wdi_csv_parquet\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n-- Load data from wdi_opencsv_gs to wdi_csv_parquet\n\nINSERT OVERWRITE TABLE wdi_csv_parquet\nSELECT *FROM wdi_opencsv_gs\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%sh\n#Inspecting  how many parquet have been created for by using HDFS commands as partitions are sub-directory in the HDFS\n hdfs dfs -ls -h /user/garslan/hive/wdi/wdi_csv_parquet\n"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\n hdfs dfs -ls -h /user/garslan/hive/wdi/wdi_opencsv_text\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "                                                                                                     Runtime comparison\n"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n\nSELECT count(countryName) FROM wdi_csv_parquet;\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT count(countryName) FROM wdi_opencsv_text;\n\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive \n-- Retrive data from wdi_csv_parquet\nSELECT year ,countryName , indicatorValue AS GDP_growth_value\nFROM wdi_csv_parquet\nWHERE indicatorName LIKE \"%GDP growth%\" AND year \u003d2015 AND countryName \u003d\u0027Canada\u0027 \n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\n-- Retrive data from wdi_opencsv_text\nSELECT year ,countryName , indicatorValue AS GDP_growth_value\nFROM wdi_opencsv_text\nWHERE indicatorName LIKE \"%GDP growth%\" AND year \u003d2015 AND countryName \u003d\u0027Canada\u0027 "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "while wdi_csv_parquet took 31 seconds, wdi_opencsv_text took 1 min 39 seconds. Columnar file optimization drastically reduced the runtime."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Highest GDP Growth\n"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive \n\n--Finding  the highest GDP growth (NY.GDP.MKTP.KD.ZG) year for each country.\nSELECT w.year ,w.countryName , w.indicatorValue AS GDP_growth_value\nFROM\n( \n   SELECT max(indicatorValue) as value, countryName\n   FROM wdi_csv_parquet\n   WHERE indicatorCode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027 AND indicatorValue!\u003d0\n   GROUP BY countryName )t\n INNER JOIN wdi_csv_parquet w ON t.value \u003d w.indicatorValue AND t.countryname\u003dw.countryName\n ORDER BY GDP_growth_value DESC;\n\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n--Executing the query using Spark to compare execution time \n\nSELECT w.year ,w.countryName , w.indicatorValue AS GDP_growth_value\nFROM\n( SELECT max(indicatorValue) as value, countryName\n   FROM wdi_csv_parquet\n   WHERE indicatorCode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027 AND indicatorValue!\u003d0\n   GROUP BY countryName\n   )m\n INNER JOIN wdi_csv_parquet w ON m.Value \u003d w.indicatorValue AND w.countryname \u003dm.countryName\n ORDER BY GDP_growth_value DESc\n\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Sort GDP by country and year\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n-- Retrieve GDP growth for all countries sorted by country name and year.\n\nSELECT countryName, year,indicatorCode, indicatorValue\nFROM wdi_csv_parquet\nWHERE  indicatorCode \u003d\u0027NY.GDP.MKTP.KD.ZG\u0027\nDISTRIBUTE  BY countryName\nSORT BY countryName , year"
    }
  ]
}